{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Input,Flatten, Convolution1D,BatchNormalization,Dense,Input,Dropout,MaxPool1D,GlobalAvgPool1D,\\\n",
    "AveragePooling1D,concatenate,Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_scores(prob,y_true,verbose=1):\n",
    "    y_pred=[]\n",
    "    for pb in prob:\n",
    "        if np.argmax(pb)==0:\n",
    "            y_pred.append(np.array([1,0]))\n",
    "        if np.argmax(pb)==1:\n",
    "            y_pred.append(np.array([0,1]))\n",
    "    y_pred=np.array(y_pred)\n",
    "    \n",
    "    accuracy=np.sum(y_pred[:,0]==y_true[:,0])/y_true.shape[0]\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    for y_p,y_t in zip(y_pred,y_true): \n",
    "        if y_p[1]==1 and y_t[1]==1:\n",
    "            tp=tp+1\n",
    "        if y_p[1]==1 and y_t[1]==0:\n",
    "            fp=fp+1\n",
    "        if y_p[1]==0 and y_t[1]==0:\n",
    "            tn=tn+1\n",
    "        if y_p[1]==0 and y_t[1]==1:\n",
    "            fn=fn+1\n",
    "    if (tp+fn)==0:\n",
    "        sensitivity='nan'\n",
    "    else:\n",
    "        sensitivity=tp/(tp+fn)\n",
    "    if (tn+fp)==0:    \n",
    "        specificity='nan'\n",
    "    else:\n",
    "        specificity=tn/(tn+fp)\n",
    "    scores={'accuracy':accuracy,'sensitivity':sensitivity,'specificity':specificity}\n",
    "    if verbose:\n",
    "        print('accuracy: {}\\t sensitivity: {}\\t specificity: {}'.format\\\n",
    "              (accuracy,sensitivity,specificity))\n",
    "    return scores\n",
    "\n",
    "def get_patient_data(ind_train,ind_test,patients):\n",
    "    patients=np.array(patients)\n",
    "    patient_train=patients[ind_train]\n",
    "    patient_test=patients[ind_test]\n",
    "    X_train=[]\n",
    "    X_test=[]\n",
    "    X_train1=[]\n",
    "    X_test1=[]\n",
    "    X_train2=[]\n",
    "    X_test2=[]\n",
    "    X_train3=[]\n",
    "    X_test3=[]\n",
    "    \n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "    for patient in patient_train:\n",
    "        patient_keys=[key for key in data_dict.keys() if patient in key]\n",
    "        for key in patient_keys:\n",
    "            segments,label_bin=data_dict[key]\n",
    "            X_train1=X_train1+list(np.reshape(segments[:,0,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_train2=X_train2+list(np.reshape(segments[:,1,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_train3=X_train3+list(np.reshape(segments[:,2,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            y_train=y_train+list(np.tile(label_bin,[segments.shape[0],1]))\n",
    "            \n",
    "                     \n",
    "    X_train1=np.array(X_train1)    \n",
    "    X_train2=np.array(X_train2)    \n",
    "    X_train3=np.array(X_train3)    \n",
    "    y_train=np.array(y_train)    \n",
    "    \n",
    "    for patient in patient_test:\n",
    "        patient_keys=[key for key in data_dict.keys() if patient in key]\n",
    "        for key in patient_keys:\n",
    "            segments,label_bin=data_dict[key]\n",
    "            X_test1=X_test1+list(np.reshape(segments[:,0,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_test2=X_test2+list(np.reshape(segments[:,1,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            X_test3=X_test3+list(np.reshape(segments[:,2,:],[segments.shape[0],segments.shape[2],1]))\n",
    "            y_test=y_test+list(np.tile(label_bin,[segments.shape[0],1]))\n",
    "    X_test1=np.array(X_test1)    \n",
    "    X_test2=np.array(X_test2)    \n",
    "    X_test3=np.array(X_test3)    \n",
    "    y_test=np.array(y_test)    \n",
    "    \n",
    "    X_train=[X_train1,X_train2,X_train3]\n",
    "    X_test=[X_test1,X_test2,X_test3]\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ECG samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict=pickle.load(open(os.path.join('..','data','imi_hc_64Hz_3_lead.bin'),'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split based on patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients=np.array(list(set([ key.split('/')[-2] for key in list(data_dict.keys())])))\n",
    "kfold_patient= KFold(n_splits=len(patients),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(filters,kernel_size,input_layer):\n",
    "    x=Convolution1D(filters=filters,kernel_size=kernel_size,padding='same',\n",
    "                    kernel_regularizer=None)(input_layer) \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPool1D(pool_size=2)(x)\n",
    "    return x\n",
    "\n",
    "def inception_block(input_layer):\n",
    "    conv3=conv_bn(4,3,input_layer)\n",
    "    conv5=conv_bn(4,5,input_layer)\n",
    "    conv7=conv_bn(4,7,input_layer)\n",
    "    conv9=conv_bn(4,9,input_layer)\n",
    "    conv16=conv_bn(4,16,input_layer)  \n",
    "    conv32=conv_bn(4,32,input_layer)\n",
    "    conv64=conv_bn(4,64,input_layer)\n",
    "    return concatenate([conv3,conv5,conv7,conv9,conv16,conv32,conv64])\n",
    "\n",
    "def get_model(input_shape):\n",
    "    input_layer1= Input(shape=input_shape)      \n",
    "    block1_ch1=inception_block(input_layer1)\n",
    "    \n",
    "    input_layer2= Input(shape=input_shape)      \n",
    "    block1_ch2=inception_block(input_layer2)\n",
    "    \n",
    "    input_layer3= Input(shape=input_shape)      \n",
    "    block1_ch3=inception_block(input_layer3)\n",
    "    \n",
    "    x=concatenate([block1_ch1,block1_ch2,block1_ch3])\n",
    "    x=GlobalAvgPool1D()(x)\n",
    "    output_layer=Dense(2,activation='softmax',kernel_regularizer=L1L2(l1=0.0,l2=0.001))(x)\n",
    "    \n",
    "    model_paper=Model(inputs=[input_layer1,input_layer2,input_layer3],outputs=output_layer)\n",
    "    model_paper.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    return model_paper\n",
    "model=get_model([196,1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cvscores=[]\n",
    "i=0\n",
    "for ind_train,ind_test in kfold_patient.split(X=patients,y=[0]*len(patients)): \n",
    "    i=i+1    \n",
    "    print('fold: {}/{}'.format(i,kfold_patient.n_splits))\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=get_patient_data(ind_train,ind_test,patients)\n",
    "\n",
    "    model_paper=get_model(X_train[0].shape[1:])\n",
    "    K.set_value(model_paper.optimizer.lr,1e-3)\n",
    "    \n",
    "    model_paper.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=200,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_test,y_test),\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='loss',min_delta=0.0,patience=10,verbose=1),\n",
    "            ReduceLROnPlateau(min_lr=1e-5,factor=.1,monitor='loss',epsilon=0.0001,patience=5,verbose=1,),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prob = model_paper.predict(X_test)\n",
    "    scores=calculate_scores(prob,y_test)\n",
    "    cvscores.append(scores)\n",
    "    \n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensitivity=[]\n",
    "specificity=[]\n",
    "accuracy=[]\n",
    "\n",
    "for score in cvscores:\n",
    "    if score['sensitivity']!='nan':\n",
    "        sensitivity.append(score['sensitivity'])\n",
    "    if score['specificity']!='nan':\n",
    "        specificity.append(score['specificity'])\n",
    "    accuracy.append(score['accuracy'])\n",
    "\n",
    "np.mean(np.array(accuracy)),np.mean(np.array(sensitivity)),np.mean(np.array(specificity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
